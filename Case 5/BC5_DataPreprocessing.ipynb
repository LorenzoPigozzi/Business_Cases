{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing data and libraries <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {\n",
    "    'ProductFamily_ID':'category',\n",
    "    'ProductCategory_ID':'category',\n",
    "    'ProductBrand_ID':'category',\n",
    "    'ProductName_ID':'category',\n",
    "    'ProductPackSKU_ID':'category',\n",
    "    'Point-of-Sale_ID':'category',\n",
    "    'Measures':'category',\n",
    "    'Value':'float32'\n",
    "}\n",
    "path = r'D:\\NOVAIMS_MAA\\NOVAIMS_MAA_2020e21_BusinessCasesDataScience_MindOverData_RetailChallenge.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(_df):\n",
    "    target_columns = ['ProductFamily_ID', 'ProductCategory_ID', 'ProductBrand_ID','ProductName_ID', 'ProductPackSKU_ID', 'Point-of-Sale_ID', 'Date']\n",
    "    cols = ['ProductFamily_ID', 'ProductCategory_ID', 'ProductBrand_ID','ProductName_ID', 'ProductPackSKU_ID', 'Point-of-Sale_ID']\n",
    "    # keeping only the number of the ID for all the varaibles\n",
    "    for col in cols:\n",
    "        _df[col]=_df[col].str.replace(r\"[^1-9]\", \"\",regex=True)\n",
    "    # splitting the chunk-dataset in 2, one for the record with quantity and one for price\n",
    "    df_units = _df[_df['Measures'] == \"Sell-out units\"]\n",
    "    df_values = _df[_df['Measures'] == \"Sell-out values\"]\n",
    "    # joining the quantity and price in the same record\n",
    "    df_join = pd.merge(df_units,df_values,on = target_columns)\n",
    "    df_join.drop(['Measures_x','Measures_y'],axis=1,inplace=True)\n",
    "    df_join.rename(columns={'Value_x':'Quantity','Value_y':'Total_Sales'},inplace=True)\n",
    "    return df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(path,nrows=2000000)\n",
    "# data = pd.read_csv('dataset/NOVAIMS_MAA_2020e21_BusinessCasesDataScience_MindOverData_RetailChallenge.csv', iterator=True, chunksize=1000)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-12b2863913bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprocessed_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the big file in smaller chunks\n",
    "#final = pd.read_csv(write,nrows=1)\n",
    "i = 0\n",
    "for gm_chunk in pd.read_csv(path,dtype=dtype_dict,chunksize=1000000):  \n",
    "    #gm_chunk.drop(\"Unnamed: 0\",axis=1,inplace = True)\n",
    "    processed_df = preprocessing(gm_chunk)\n",
    "    if i == 0:\n",
    "        final = processed_df\n",
    "        i +=1\n",
    "    else:\n",
    "        i +=1\n",
    "        if i%5 == 0:\n",
    "            print(i)\n",
    "        final = pd.concat([final,processed_df],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_processed = r'D:\\NOVAIMS_MAA\\NOVAIMS_MAA_final_1.csv'\n",
    "final.to_csv(write_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data engineering <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(_df):\n",
    "    target_columns = ['ProductFamily_ID', 'ProductCategory_ID', 'ProductBrand_ID','ProductName_ID', 'ProductPackSKU_ID', 'Point-of-Sale_ID', 'Date']\n",
    "    cols = ['ProductFamily_ID', 'ProductCategory_ID', 'ProductBrand_ID','ProductName_ID', 'ProductPackSKU_ID', 'Point-of-Sale_ID']\n",
    "    # keeping only the number of the ID for all the varaibles\n",
    "    for col in cols:\n",
    "        _df[col]=_df[col].str.replace(r\"[^1-9]\", \"\",regex=True)\n",
    "    # splitting the chunk-dataset in 2, one for the record with quantity and one for price\n",
    "    df_units = _df[_df['Measures'] == \"Sell-out units\"]\n",
    "    df_values = _df[_df['Measures'] == \"Sell-out values\"]\n",
    "    # joining the quantity and price in the same record\n",
    "    df_join = pd.merge(df_units,df_values,on = target_columns)\n",
    "    df_join.drop(['Measures_x','Measures_y'],axis=1,inplace=True)\n",
    "    df_join.rename(columns={'Value_x':'Quantity','Value_y':'Total_Sales'},inplace=True)\n",
    "    return df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preprocessing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same number of 'Sell-out values' and 'Sell-out units', meaning that it's always record byt pair of records.\n",
    "\n",
    "\\\n",
    "**Idea**\\\n",
    "Creating for each combination of ProductFamily_ID, ProductCategory_ID, ProductBrand_ID, ProductName_ID, ProductPackSKU_ID, Point-of-Sale_ID and Date one column for the quantity and one column for the price in a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
